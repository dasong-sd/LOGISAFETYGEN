[
    {
        "definition": [],
        "scope": "Certain Al systems",
        "policy_description": "Certain Al systems must undergo a rigorous conformity assessment, which may involve third-party evaluation, to ensure compliance with the applicable rules.",
        "reference": [
            "health_related_ai_in_the_ai_act.summary"
        ]
    },
    {
        "definition": [
            "unacceptable risks (e.g. certain Al used for biometric surveillance)"
        ],
        "scope": "Al practices posing unacceptable risks",
        "policy_description": "Al practices posing unacceptable risks are prohibited (e.g. certain Al used for biometric surveillance).",
        "reference": [
            "health_related_ai_in_the_ai_act.high_risk_ai"
        ]
    },
    {
        "definition": [
            "High-risk Al systems (e.g. Al diagnostic tools)"
        ],
        "scope": "High-risk Al systems",
        "policy_description": "High-risk Al systems (e.g. Al diagnostic tools), must comply with certain safety and quality requirements, and operators have specific obligations regarding their use.",
        "reference": [
            "health_related_ai_in_the_ai_act.high_risk_ai"
        ]
    },
    {
        "definition": [
            "low-risk AI",
            "medical devices that are not required to undergo a third-party conformity assessment (Class I)",
            "This includes a wide range of health-related Al systems, deployed for purposes related to wellbeing, health promotion, or activity monitoring.",
            "Concrete examples are mobile health apps monitoring mood and wellbeing or offering personalized diet recommendations based on user data, and Al-based sensors used for assisted living for older people."
        ],
        "scope": "These systems",
        "policy_description": "These systems only need to comply with certain transparency requirements because of their direct interaction with individuals, such as chatbots providing advice on wellbeing.",
        "reference": [
            "health_related_ai_in_the_ai_act.low_risk_and_minimal_risk_ai"
        ]
    },
    {
        "definition": [],
        "scope": "providers and deployers... of their staff using (low and high-risk) Al systems",
        "policy_description": "Moreover, Article 4 requires providers and deployers to take measures to ensure a sufficient level of Al literacy of their staff using (low and high-risk) Al systems.",
        "reference": [
            "health_related_ai_in_the_ai_act.low_risk_and_minimal_risk_ai"
        ]
    },
    {
        "definition": [
            "general-purpose Al models, such as Large Language Models (LLMs) capable of generating text and images on the basis of user input"
        ],
        "scope": "these Al models",
        "policy_description": "Therefore, these Al models need to meet certain transparency requirements, such as disclosure of technical documentation and a description of the data used for training.",
        "reference": [
            "health_related_ai_in_the_ai_act.general_purpose_ai_models"
        ]
    },
    {
        "definition": [
            "some general-purpose Al models... that can pose systemic risks due to high-impact powerful systems (e.g. GPT-4)"
        ],
        "scope": "these",
        "policy_description": "As some general-purpose Al models can pose systemic risks due to high-impact powerful systems (e.g. GPT-4), extra requirements apply to these, such as performing model evaluations and documenting and reporting serious incidents.",
        "reference": [
            "health_related_ai_in_the_ai_act.general_purpose_ai_models"
        ]
    },
    {
        "definition": [
            "In these cases' refers to when 'healthcare organisations such as hospitals and long- term care homes are developing Al systems for their own use' or when 'National public health authorities are also increasingly putting Al systems into service...'"
        ],
        "scope": "healthcare organisations and public health authorities",
        "policy_description": "In these cases, healthcare organisations and public health authorities must comply with the requirements for providers in Table 1, depending on the risk classification of the AI system.",
        "reference": [
            "obligations_for_providers"
        ]
    },
    {
        "definition": [
            "a deployer as 'a natural or legal person, public authority, agency or other body using an Al system under its authority'"
        ],
        "scope": "health professionals using Al for healthcare activities",
        "policy_description": "This means that health professionals using Al for healthcare activities must comply with the rules stipulated for deployers.",
        "reference": [
            "obligations_for_deployers"
        ]
    },
    {
        "definition": [
            "This' refers to 'the fundamental rights impact assessment of Article 27.'"
        ],
        "scope": "deployers... before deploying the AI",
        "policy_description": "This requires deployers - before deploying the AI to identify the risks that could emerge for fundamental rights and design measures to mitigate potential harm.",
        "reference": [
            "obligations_for_deployers"
        ]
    },
    {
        "definition": [
            "the fundamental rights impact assessment"
        ],
        "scope": "all deployers public or private - using AI to determine access to and pricing of life and health insurance",
        "policy_description": "By exemption, all deployers public or private - using AI to determine access to and pricing of life and health insurance must perform the fundamental rights impact assessment.",
        "reference": [
            "obligations_for_deployers"
        ]
    },
    {
        "definition": [],
        "scope": "any natural or legal person that suspects an infringement of the AI Act - including patients",
        "policy_description": "However, Article 85 does introduce the right to lodge a complaint with a market surveillance authority for any natural or legal person that suspects an infringement of the AI Act - including patients.",
        "reference": [
            "individual_rights_for_persons_affected_by_ai"
        ]
    },
    {
        "definition": [
            "right to explanation of individual decision-making, which entails 'the right to obtain from the deployer clear and meaningful explanations of the role of the Al system in the decision-making procedure and the main elements of the decision'"
        ],
        "scope": "the deployer",
        "policy_description": "Moreover, Article 86 introduces the right to explanation of individual decision-making, which entails 'the right to obtain from the deployer clear and meaningful explanations of the role of the Al system in the decision-making procedure and the main elements of the decision'.",
        "reference": [
            "individual_rights_for_persons_affected_by_ai"
        ]
    },
    {
        "definition": [
            "the right to informed consent, as protected in all EU Member States"
        ],
        "scope": "the patient",
        "policy_description": "It is important to note that the right to informed consent, as protected in all EU Member States, does entitle the patient to information about the medical treatment in a manner that is sufficient to make an informed decision about whether to proceed.",
        "reference": [
            "individual_rights_for_persons_affected_by_ai"
        ]
    }
]